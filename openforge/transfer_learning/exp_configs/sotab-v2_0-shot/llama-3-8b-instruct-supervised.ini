[io]
data_dir = /nfs/turbo/coe-jag/congtj/openforge/sotab_v2
output_dir = /home/congtj/openforge/exps/sotab_v2/transfer_learning/llm2vec/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised

[encoding]
base_model_id = McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp
lora_model_id = McGill-NLP/LLM2Vec-Meta-Llama-3-8B-Instruct-mntp-supervised
pooling_mode = mean
max_length = 512
batch_size = 4
