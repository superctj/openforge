[io]
data_dir = /nfs/turbo/coe-jag/congtj/openforge/sotab_v2
output_dir = /home/congtj/openforge/exps/sotab_v2/transfer_learning/llm2vec/LLM2Vec-Mistral-7B-Instruct-v2-mntp-unsup-simcse

[encoding]
base_model_id = McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp
lora_model_id = McGill-NLP/LLM2Vec-Mistral-7B-Instruct-v2-mntp-unsup-simcse
pooling_mode = mean
max_length = 512
batch_size = 32
