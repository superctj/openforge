[exp]
data_dir = /nfs/turbo/coe-jag/congtj/openforge/sotab_v2
output_dir = /nfs/turbo/coe-jag/congtj/openforge/finetuned_models/qwen-2.5-7b_lora/sotab_v2/no_class_imbalance_handling
random_seed = 42

[llm]
model_id = Qwen/Qwen2.5-7B
handle_class_imbalance = False
target_modules = q_proj, v_proj
r = 8
lora_alpha = 16
lora_dropout = 0.1
num_train_epochs = 20
learning_rate = 2e-4
weight_decay = 0.01
train_batch_size = 8
eval_batch_size = 16
